{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# predict_emotion.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from transformers import BertTokenizer, TFBertModel # Only if using BERT model\n",
        "\n",
        "# Import configurations and helper functions\n",
        "from config import (\n",
        "    TEXT_COLUMN, LABEL_COLUMNS, MODEL_TYPE,\n",
        "    MAX_SEQUENCE_LENGTH, BERT_MAX_LEN,\n",
        "    SAVE_DIR, MODEL_SAVE_PATH, TOKENIZER_SAVE_PATH\n",
        ")\n",
        "from data_handler import clean_text, tokenize_and_pad_sequences, load_tokenizer\n",
        "from model_architectures import BahdanauAttention # Required for loading BiGRU_Attention model\n",
        "\n",
        "def load_emotion_model():\n",
        "    \"\"\"\n",
        "    Loads the saved Keras emotion classification model.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: The loaded model.\n",
        "    Raises:\n",
        "        FileNotFoundError: If the model file does not exist.\n",
        "        ValueError: If model type is unknown or custom objects are missing.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(MODEL_SAVE_PATH):\n",
        "        raise FileNotFoundError(f\"Error: Model not found at '{MODEL_SAVE_PATH}'. Please train the model first.\")\n",
        "\n",
        "    print(f\"Loading {MODEL_TYPE} model from {MODEL_SAVE_PATH}...\")\n",
        "    try:\n",
        "        custom_objects = {}\n",
        "        if MODEL_TYPE == 'BiGRU_Attention':\n",
        "            custom_objects = {'BahdanauAttention': BahdanauAttention}\n",
        "\n",
        "        model = tf.keras.models.load_model(MODEL_SAVE_PATH, custom_objects=custom_objects)\n",
        "        print(\"Model loaded successfully.\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error loading model: {e}. Make sure MODEL_TYPE in config.py matches the saved model and custom objects are correctly defined.\")\n",
        "\n",
        "def predict_emotion(lyrics, model, tokenizer=None, bert_tokenizer=None, bert_model=None):\n",
        "    \"\"\"\n",
        "    Predicts emotions for a given lyric text.\n",
        "\n",
        "    Args:\n",
        "        lyrics (str): The song lyric text to predict.\n",
        "        model (tf.keras.Model): The loaded Keras model.\n",
        "        tokenizer (tf.keras.preprocessing.text.Tokenizer, optional): Pre-fitted Keras tokenizer (for BiGRU).\n",
        "        bert_tokenizer (transformers.BertTokenizer, optional): BERT tokenizer (for BERT_XLSTM).\n",
        "        bert_model (transformers.TFBertModel, optional): BERT model (for BERT_XLSTM).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with emotion labels and their predicted probabilities.\n",
        "    \"\"\"\n",
        "    cleaned_lyrics = clean_text(lyrics)\n",
        "    processed_input = None\n",
        "\n",
        "    if MODEL_TYPE == 'BiGRU_Attention':\n",
        "        if tokenizer is None:\n",
        "            raise ValueError(\"Tokenizer must be provided for BiGRU_Attention model prediction.\")\n",
        "        sequences = tokenizer.texts_to_sequences([cleaned_lyrics])\n",
        "        processed_input = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post'\n",
        "        )\n",
        "    elif MODEL_TYPE == 'BERT_XLSTM':\n",
        "        if bert_tokenizer is None or bert_model is None:\n",
        "            print(\"Initializing BERT Tokenizer and Model for prediction...\")\n",
        "            bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "            bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "            print(\"BERT components initialized.\")\n",
        "        tokens = bert_tokenizer([cleaned_lyrics], padding='max_length', truncation=True,\n",
        "                                max_length=BERT_MAX_LEN, return_tensors='tf')\n",
        "        # Use only the CLS token embedding\n",
        "        outputs = bert_model(tokens)['last_hidden_state'][:, 0, :]\n",
        "        processed_input = outputs.numpy()\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown MODEL_TYPE '{MODEL_TYPE}'. Cannot preprocess for prediction.\")\n",
        "\n",
        "    if processed_input is None:\n",
        "        return {\"error\": \"Failed to process input for prediction.\"}\n",
        "\n",
        "    # Make prediction\n",
        "    prediction_proba = model.predict(processed_input)[0] # Get the first (and only) sample's prediction\n",
        "\n",
        "    # Map probabilities to labels\n",
        "    results = {}\n",
        "    for i, label in enumerate(LABEL_COLUMNS):\n",
        "        results[label] = float(prediction_proba[i]) # Convert numpy.float32 to standard float\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = None\n",
        "    tokenizer = None\n",
        "    bert_tokenizer_pred = None\n",
        "    bert_model_pred = None\n",
        "\n",
        "    try:\n",
        "        model = load_emotion_model()\n",
        "\n",
        "        if MODEL_TYPE == 'BiGRU_Attention':\n",
        "            tokenizer = load_tokenizer(TOKENIZER_SAVE_PATH)\n",
        "        elif MODEL_TYPE == 'BERT_XLSTM':\n",
        "            # Initialize BERT tokenizer and model once for prediction\n",
        "            print(\"Initializing BERT Tokenizer and Model for prediction...\")\n",
        "            bert_tokenizer_pred = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "            bert_model_pred = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "            print(\"BERT components initialized.\")\n",
        "\n",
        "        sample_lyrics_1 = \"I feel so happy today, the sun is shining, and everything is going my way. Full of joy!\"\n",
        "        sample_lyrics_2 = \"A shadow falls upon my heart, a heavy weight, tearing me apart. Full of sorrow and despair.\"\n",
        "        sample_lyrics_3 = \"My blood boils, a fiery rage, I will not stand for this injustice anymore. Unleash the fury!\"\n",
        "        sample_lyrics_4 = \"I dream of you endlessly, your presence consumes my thoughts. A longing that never fades, an undeniable pull.\"\n",
        "\n",
        "\n",
        "        print(\"\\n--- Prediction for Sample 1 ---\")\n",
        "        predictions = predict_emotion(sample_lyrics_1, model, tokenizer, bert_tokenizer_pred, bert_model_pred)\n",
        "        for label, prob in predictions.items():\n",
        "            print(f\"- {label}: {prob:.4f}\")\n",
        "\n",
        "        print(\"\\n--- Prediction for Sample 2 ---\")\n",
        "        predictions = predict_emotion(sample_lyrics_2, model, tokenizer, bert_tokenizer_pred, bert_model_pred)\n",
        "        for label, prob in predictions.items():\n",
        "            print(f\"- {label}: {prob:.4f}\")\n",
        "\n",
        "        print(\"\\n--- Prediction for Sample 3 ---\")\n",
        "        predictions = predict_emotion(sample_lyrics_3, model, tokenizer, bert_tokenizer_pred, bert_model_pred)\n",
        "        for label, prob in predictions.items():\n",
        "            print(f\"- {label}: {prob:.4f}\")\n",
        "\n",
        "        print(\"\\n--- Prediction for Sample 4 ---\")\n",
        "        predictions = predict_emotion(sample_lyrics_4, model, tokenizer, bert_tokenizer_pred, bert_model_pred)\n",
        "        for label, prob in predictions.items():\n",
        "            print(f\"- {label}: {prob:.4f}\")\n",
        "\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        print(f\"Error during prediction setup: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "ld9Jlpi8m9eJ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}