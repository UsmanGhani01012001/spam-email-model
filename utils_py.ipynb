{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# utils.py\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    Plots the training and validation loss and other metrics over epochs.\n",
        "\n",
        "    Args:\n",
        "        history (keras.callbacks.History): The history object returned by model.fit().\n",
        "    \"\"\"\n",
        "    print(\"\\nGenerating training history plots...\")\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Precision (if available)\n",
        "    if 'precision' in history.history and 'val_precision' in history.history:\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['precision'], label='Training Precision')\n",
        "        plt.plot(history.history['val_precision'], label='Validation Precision')\n",
        "        plt.title('Training and Validation Precision')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "    elif 'accuracy' in history.history and 'val_accuracy' in history.history:\n",
        "        # Fallback to Accuracy if precision is not tracked (e.g., for BERT model compilation with 'accuracy')\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title('Training and Validation Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "    # You can add more subplots for Recall, F1-score if you modify metrics to track them directly.\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"Plots displayed.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "F8pJJj3jnDCm"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}